{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W4_DeepMLPs",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arashash/Deep-Learning-Course-Tutorials/blob/main/W4_DeepMLPs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "kTA6eSOPUfmw"
      },
      "source": [
        "\n",
        "#Week 4: Deep Multi-layer Perceptrons (MLPs)\n",
        "**By Arash Ash, adapted from Neuromatch Academy contents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1obvRMj7Ufmz"
      },
      "source": [
        "---\n",
        "# Tutorial Objectives\n",
        "In this tutorial, we will dive deeper into MLPs and see more of their mathematical and practical aspects. Today we are going to see why MLPs:\n",
        "\n",
        "* can be deep or wide\n",
        "* dependant on transfer functions\n",
        "* sensitive to initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "YZ94cUw0Ufm1"
      },
      "source": [
        "---\n",
        "# Setup\n",
        "\n",
        "This is a GPU free notebook!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "7YhSdqUWUfm1"
      },
      "source": [
        "# @title Install dependencies\n",
        "!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n",
        "from evaltools.airtable import AirtableForm\n",
        "\n",
        "atform = AirtableForm('appn7VdPRseSoMXEG','W1D3_T2','https://portal.neuromatchacademy.org/api/redirect/to/49e16345-65a5-4616-ba63-568ca06cab78')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "ypII82EPUfm2"
      },
      "source": [
        "# Imports\n",
        "import pathlib\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "bicaTLBPUfm3"
      },
      "source": [
        "# @title Figure Settings\n",
        "import ipywidgets as widgets       # interactive display\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")\n",
        "my_layout = widgets.Layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Th-CsIU_Ufm5"
      },
      "source": [
        "# @title Plotting functions\n",
        "def imshow(img):\n",
        "  img = img / 2 + 0.5     # unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.axis(False)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def sample_grid(M=500, x_max=2.0):\n",
        "  ii, jj = torch.meshgrid(torch.linspace(-x_max, x_max,M),\n",
        "                          torch.linspace(-x_max, x_max, M))\n",
        "  X_all = torch.cat([ii.unsqueeze(-1),\n",
        "                     jj.unsqueeze(-1)],\n",
        "                     dim=-1).view(-1, 2)\n",
        "  return X_all\n",
        "\n",
        "\n",
        "def plot_decision_map(X_all, y_pred, X_test, y_test,\n",
        "                      M=500, x_max=2.0, eps=1e-3):\n",
        "  decision_map = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "  for i in range(len(X_test)):\n",
        "    indeces = (X_all[:, 0] - X_test[i, 0])**2 + (X_all[:, 1] - X_test[i, 1])**2 < eps    # [TO-DO]\n",
        "    decision_map[indeces] = (K + y_test[i]).long()\n",
        "\n",
        "  decision_map = decision_map.view(M, M).cpu()\n",
        "  plt.imshow(decision_map, extent=[-x_max, x_max, -x_max, x_max], cmap='jet')\n",
        "  plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "qLQO-xWhUfm5"
      },
      "source": [
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# for DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "i8GXtGzWUfm5"
      },
      "source": [
        "# @title Set device (GPU or CPU). Execute `set_device()`\n",
        "# especially if torch modules used.\n",
        "\n",
        "# inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"GPU is not enabled in this notebook. \\n\"\n",
        "          \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n",
        "          \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook. \\n\"\n",
        "          \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n",
        "          \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n",
        "\n",
        "  return device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "uGHx1LuTUfm6"
      },
      "source": [
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "j2LoKr9DUfm6"
      },
      "source": [
        "# @title Download of the Animal Faces dataset\n",
        "# @markdown Animal faces consists of 16,130 32x32 images belonging to 3 classes\n",
        "import requests, os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print(\"Start downloading and unzipping `AnimalFaces` dataset...\")\n",
        "name = 'AnimalFaces32x32'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/kgfvj/download\"\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "with open(fname, 'wb') as fh:\n",
        "  fh.write(r.content)\n",
        "\n",
        "with ZipFile(fname, 'r') as zfile:\n",
        "  zfile.extractall(f\"./{name}\")\n",
        "\n",
        "if os.path.exists(fname):\n",
        "  os.remove(fname)\n",
        "else:\n",
        "  print(f\"The file {fname} does not exist\")\n",
        "\n",
        "os.chdir(name)\n",
        "print(\"Download completed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DWW0PZKVrNr"
      },
      "source": [
        "# MLP from Week 3\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, actv, input_feature_num, hidden_unit_nums, output_feature_num):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_feature_num = input_feature_num # save the input size for reshapinng later\n",
        "    self.mlp = nn.Sequential() # Initialize layers of MLP\n",
        "\n",
        "    in_num = input_feature_num # initialize the temporary input feature to each layer\n",
        "    for i in range(len(hidden_unit_nums)): # Loop over layers and create each one\n",
        "      out_num = hidden_unit_nums[i] # assign the current layer hidden unit from list\n",
        "      layer = nn.Linear(in_num, out_num) # use nn.Linear to define the layer\n",
        "      in_num = out_num # assign next layer input using current layer output\n",
        "      self.mlp.add_module(f\"Linear_{i}\", layer) # append layer to the model with a name\n",
        "\n",
        "      actv_layer = eval(f\"nn.{actv}\") # Assign activation function (eval allows us to instantiate object from string)\n",
        "      self.mlp.add_module(f\"Activation_{i}\", actv_layer) # append activation to the model with a name\n",
        "\n",
        "    out_layer = nn.Linear(in_num, output_feature_num) # Create final layer\n",
        "    self.mlp.add_module('Output_Linear', out_layer) # append the final layer\n",
        "\n",
        "  def forward(self, x):\n",
        "    # reshape inputs to (batch_size, input_feature_num)\n",
        "    # just in case the input vector is not 2D, like an image!\n",
        "    x = x.view(-1, self.input_feature_num)\n",
        "\n",
        "    logits = self.mlp(x) # forward pass of MLP\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPf1QN7QavFU"
      },
      "source": [
        "## Section 1: Classification with MLPs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T4_sXiNazOG"
      },
      "source": [
        "The main loss function we could use out of the box for multi-class classification for `N` samples and `C` number of classes is:\n",
        "* CrossEntropyLoss:\n",
        "This criterion expects a batch of predictions `x` with shape `(N, C)` and class index in the range $[0, C-1]$ as the target (label) for each `N` samples, hence a batch of `labels` with shape `(N, )`. There are other optional parameters like class weights and class ignores. Feel free to check the PyTorch documentation [here](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) for more detail. Additionally, [here](https://sparrow.dev/cross-entropy-loss-in-pytorch/) you can learn where is appropriate to use the CrossEntropyLoss.\n",
        "\n",
        "To get CrossEntropyLoss of a sample $i$, we could first calculate $-\\log(\\text{softmax(x}))$ and then take the element corresponding to $\\text { labels }_i$ as the loss. However, due to numerical stability, we implement this more stable equivalent form,\n",
        "\n",
        "\\begin{equation}\n",
        "\\operatorname{loss}(x_i, \\text { labels }_i)=-\\log \\left(\\frac{\\exp (x[\\text { labels }_i])}{\\sum_{j} \\exp (x[j])}\\right)=-x_i[\\text { labels }_i]+\\log \\left(\\sum_{j=1}^C \\exp (x_i[j])\\right)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhDAyKGOa1j3"
      },
      "source": [
        "### Coding Exercise 2.1: Implement Batch Cross Entropy Loss\n",
        "\n",
        "To recap, since we will be doing batch learning, we'd like a loss function that given:\n",
        "* a batch of predictions `x` with shape `(N, C)` \n",
        "* a batch of `labels` with shape `(N, )` that ranges from `0` to `C-1`\n",
        "\n",
        "returns the average loss $L$ calculated according to:\n",
        "\n",
        "\\begin{align}\n",
        "loss(x_i, \\text { labels }_i) &= -x_i[\\text { labels }_i]+\\log \\left(\\sum_{j=1}^C \\exp (x_i[j])\\right) \\\\\n",
        "L &= \\frac{1}{N} \\sum_{i=1}^{N}{loss(x_i, \\text { labels }_i)}\n",
        "\\end{align}\n",
        "\n",
        "Steps:\n",
        "\n",
        "1.   Use indexing operation to get predictions of class corresponding to the labels (i.e., $x_i[\\text { labels }_i]$)\n",
        "2.   Compute $loss(x_i, \\text { labels }_i)$ vector (`losses`) using `torch.log()` and `torch.exp()` without Loops!\n",
        "3. Return the average of the loss vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6zF2Wzna4HU"
      },
      "source": [
        "def cross_entropy_loss(x, labels):\n",
        "  # x is the model predictions we'd like to evaluate using lables\n",
        "  x_of_labels = torch.zeros(len(labels))\n",
        "  ####################################################################\n",
        "  # Fill in missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Cross Entropy Loss\")\n",
        "  ####################################################################\n",
        "  # 1. prediction for each class corresponding to the label\n",
        "  for i, label in enumerate(labels):\n",
        "    x_of_labels[i] = x[i, label]\n",
        "  # 2. loss vector for the batch\n",
        "  losses = ...\n",
        "  # 3. Return the average of the loss vector\n",
        "  avg_loss = ...\n",
        "\n",
        "  return avg_loss\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 2.1: Implement Batch Cross Entropy Loss')\n",
        "\n",
        "\n",
        "labels = torch.tensor([0, 1])\n",
        "x = torch.tensor([[10.0, 1.0, -1.0, -20.0],  # correctly classified\n",
        "                  [10.0, 10.0, 2.0, -10.0]])  # Not correctly classified\n",
        "CE = nn.CrossEntropyLoss()\n",
        "pytorch_loss = CE(x, labels).item()\n",
        "## Uncomment below to test your function\n",
        "# our_loss = cross_entropy_loss(x, labels).item()\n",
        "# print(f'Our CE loss: {our_loss:0.8f}, Pytorch CE loss: {pytorch_loss:0.8f}')\n",
        "# print(f'Difference: {np.abs(our_loss - pytorch_loss):0.8f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSeMYg6ba-uw"
      },
      "source": [
        "## Section 1.2: Spiral classification dataset\n",
        "Before we could start optimizing these loss functions, we need a dataset!\n",
        "\n",
        "Let's turn this fancy-looking equation into a classification dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "010O9xJPbCL6"
      },
      "source": [
        "\\begin{equation}\n",
        "\\begin{array}{c}\n",
        "X_{k}(t)=t\\left(\\begin{array}{c}\n",
        "\\sin \\left[\\frac{2 \\pi}{K}\\left(2 t+k-1\\right)\\right]+\\mathcal{N}\\left(0, \\sigma\\right) \\\\\n",
        "\\cos \\left[\\frac{2 \\pi}{K}\\left(2 t+k-1\\right)\\right]+\\mathcal{N}\\left(0, \\sigma\\right) \n",
        "\\end{array}\\right)\n",
        "\\end{array}, \\quad 0 \\leq t \\leq 1, \\quad k=1, \\ldots, K\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjJQek6ubGgq"
      },
      "source": [
        "def create_spiral_dataset(K, sigma, N):\n",
        "\n",
        "  # Initialize t, X, y\n",
        "  t = torch.linspace(0, 1, N)\n",
        "  X = torch.zeros(K*N, 2)\n",
        "  y = torch.zeros(K*N)\n",
        "\n",
        "  # Create data\n",
        "  for k in range(K):\n",
        "    X[k*N:(k+1)*N, 0] = t*(torch.sin(2*np.pi/K*(2*t+k)) + sigma*torch.randn(N))\n",
        "    X[k*N:(k+1)*N, 1] = t*(torch.cos(2*np.pi/K*(2*t+k)) + sigma*torch.randn(N))\n",
        "    y[k*N:(k+1)*N] = k\n",
        "\n",
        "  return X, y\n",
        "\n",
        "\n",
        "# Set parameters\n",
        "K = 4\n",
        "sigma = 0.16\n",
        "N = 1000\n",
        "\n",
        "set_seed(seed=SEED)\n",
        "X, y = create_spiral_dataset(K, sigma, N)\n",
        "plt.scatter(X[:, 0], X[:, 1], c = y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmIJgTibKDy"
      },
      "source": [
        "## Section 1.3: Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9D9b3GMbPHk"
      },
      "source": [
        "### Coding Exercise 2.3: Implement it for a classfication task\n",
        "Now that we have the Spiral dataset and a loss function, it's your turn to implement a simple train/test split for training and validation.\n",
        "\n",
        "Steps to follow: \n",
        "  * Dataset shuffle\n",
        "  * Train/Test split (20% for test)\n",
        "  * Dataloader definition\n",
        "  * Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-y6UfDXbJlx"
      },
      "source": [
        "def shuffle_and_split_data(X, y, seed):\n",
        "  # set seed for reproducibility\n",
        "  torch.manual_seed(seed)\n",
        "  # Number of samples\n",
        "  N = X.shape[0]\n",
        "  ####################################################################\n",
        "  # Fill in missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Shuffle & split data\")\n",
        "  ####################################################################\n",
        "  # Shuffle data\n",
        "  shuffled_indices = ...   # get indices to shuffle data, could use torch.randperm\n",
        "  X = X[shuffled_indices]\n",
        "  y = y[shuffled_indices]\n",
        "\n",
        "  # Split data into train/test\n",
        "  test_size = ...    # assign test datset size using 20% of samples\n",
        "  X_test = X[:test_size]\n",
        "  y_test = y[:test_size]\n",
        "  X_train = X[test_size:]\n",
        "  y_train = y[test_size:]\n",
        "\n",
        "  return X_test, y_test, X_train, y_train\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 2.3: Implement for a classfication task')\n",
        "\n",
        "\n",
        "## Uncomment below to test your function\n",
        "# X_test, y_test, X_train, y_train = shuffle_and_split_data(X, y, seed=SEED)\n",
        "# plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
        "# plt.title('Test data')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM1eq-5XbV7i"
      },
      "source": [
        "And we need to make a Pytorch data loader out of it. Data loading in PyTorch can be separated in 2 parts:\n",
        "* Data must be wrapped on a Dataset parent class where the methods __getitem__ and __len__ must be overrided. Note that at this point the data is not loaded on memory. PyTorch will only load what is needed to the memory. Here `TensorDataset` does this for us directly.\n",
        "* Use a Dataloader that will actually read the data in batches and put into memory. Also, the option of `num_workers > 0` allows multithreading, which prepares multiple batches in the queue to speed things up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZKyHdBjbVaW"
      },
      "source": [
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "batch_size = 128\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
        "                         shuffle=False, num_workers=2,\n",
        "                         worker_init_fn=seed_worker,\n",
        "                         generator=g_seed)\n",
        "\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, drop_last=True,\n",
        "                        shuffle=True, num_workers=2,\n",
        "                         worker_init_fn=seed_worker,\n",
        "                         generator=g_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETKLWDllbZjz"
      },
      "source": [
        "Let's write a general-purpose training and evaluation code and keep it in our pocket for next tutorial as well. So make sure you review it to see what it does.\n",
        "\n",
        "Note that `model.train()` tells your model that you are training the model. So layers like dropout, batchnorm etc. which behave different on the train and test procedures know what is going on and hence can behave accordingly. And to turn off training mode we set `model.eval()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnsc_z-Zbbhd"
      },
      "source": [
        "def train_test_classification(net, criterion, optimizer, train_loader,\n",
        "                              test_loader, num_epochs=1, verbose=True,\n",
        "                              training_plot=False, device='cpu'):\n",
        "\n",
        "  net.train()\n",
        "  training_losses = []\n",
        "  for epoch in tqdm(range(num_epochs)):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device).float()\n",
        "      labels = labels.to(device).long()\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = net(inputs)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print statistics\n",
        "      if verbose:\n",
        "        training_losses += [loss.item()]\n",
        "\n",
        "  net.eval()\n",
        "  def test(data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in data_loader:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device).float()\n",
        "      labels = labels.to(device).long()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    return total, acc\n",
        "\n",
        "  train_total, train_acc = test(train_loader)\n",
        "  test_total, test_acc = test(test_loader)\n",
        "\n",
        "  if verbose:\n",
        "    print(f\"Accuracy on the {train_total} training samples: {train_acc:0.2f}\")\n",
        "    print(f\"Accuracy on the {test_total} testing samples: {test_acc:0.2f}\")\n",
        "\n",
        "  if training_plot:\n",
        "    plt.plot(training_losses)\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Training loss')\n",
        "    plt.show()\n",
        "\n",
        "  return train_acc, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfpO6cwcbfRI"
      },
      "source": [
        "### Think! 1.3.1: What's the point of .eval() and .train()?\n",
        "\n",
        "Is it necessary to use `net.train()` and `net.eval()` for our MLP model? why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6jnboxJbjqy"
      },
      "source": [
        "Now let's put everything together and train your first deep-ish model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6_Wt4idblte"
      },
      "source": [
        "set_seed(SEED)\n",
        "net = Net('ReLU()', X_train.shape[1], [128], K).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "num_epochs = 100\n",
        "\n",
        "_, _ = train_test_classification(net, criterion, optimizer, train_loader,\n",
        "                                 test_loader, num_epochs=num_epochs,\n",
        "                                 training_plot=True, device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfFYL3cqboWv"
      },
      "source": [
        "And finally, let's visualize the learned decision-map. We know you're probably running out of time, so we won't make you write code now! But make sure you have reviewed it since we'll start with another visualization technique next time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmUGToPrbqa7"
      },
      "source": [
        "def sample_grid(M=500, x_max=2.0):\n",
        "  ii, jj = torch.meshgrid(torch.linspace(-x_max, x_max, M),\n",
        "                          torch.linspace(-x_max, x_max, M))\n",
        "  X_all = torch.cat([ii.unsqueeze(-1),\n",
        "                     jj.unsqueeze(-1)],\n",
        "                     dim=-1).view(-1, 2)\n",
        "  return X_all\n",
        "\n",
        "\n",
        "def plot_decision_map(X_all, y_pred, X_test, y_test,\n",
        "                      M=500, x_max=2.0, eps=1e-3):\n",
        "  decision_map = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "  for i in range(len(X_test)):\n",
        "    indices = (X_all[:, 0] - X_test[i, 0])**2 + (X_all[:, 1] - X_test[i, 1])**2 < eps\n",
        "    decision_map[indices] = (K + y_test[i]).long()\n",
        "\n",
        "  decision_map = decision_map.view(M, M)\n",
        "  plt.imshow(decision_map, extent=[-x_max, x_max, -x_max, x_max], cmap='jet')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLe9PRGBbtWi"
      },
      "source": [
        "X_all = sample_grid()\n",
        "y_pred = net(X_all)\n",
        "plot_decision_map(X_all, y_pred, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4eBt--pbvht"
      },
      "source": [
        "### Think! 1.3.2: Does it generalize well?\n",
        "Do you think this model is performing well outside its training distribution? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "2wY2hDRHUfm7"
      },
      "source": [
        "---\n",
        "# Section 2: Wider vs deeper networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "Rl54HyoFUfm7",
        "cellView": "form"
      },
      "source": [
        "# @title Video 1: Deep Expressivity\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV19f4y157vG\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"g8JuGrNk9ag\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 1: Deep Expressivity')\n",
        "\n",
        "# display(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "fJ7wvUMgUfm7"
      },
      "source": [
        "## Coding Exercise 1: Wide vs. Deep while keeping number of parameters same\n",
        "Let's find the optimal number of hidden layers under a fixed number of parameters constraint!\n",
        "\n",
        "But first, we need a model parameter counter. You could iterate over the model layers by calling `.parameters()` and then use `.numel()` to count the layer parameters. Also, you can use [`requires_grad`](https://pytorch.org/docs/stable/notes/autograd.html) attribute to make sure it's a trainable parameter. E.g.,\n",
        "\n",
        "```python\n",
        "x = torch.ones(10, 5, requires_grad=True)\n",
        "```\n",
        "\n",
        "After defining the counter function, we will step by step increase the depth and then iterate over the possible number of hidden units (assuming same for all hidden layers); then using our parameter counter choose the number of hidden units that results in overall close to `max_par_count` parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "QNKP3qvlUfm8"
      },
      "source": [
        "def run_depth_optimizer(max_par_count, max_hidden_layer, device):\n",
        "  ####################################################################\n",
        "  # Fill in all missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Define the depth optimizer function\")\n",
        "  ###################################################################\n",
        "\n",
        "  def count_parameters(model):\n",
        "    par_count = 0\n",
        "    for p in model.parameters():\n",
        "      if p.requires_grad:\n",
        "        par_count += ...\n",
        "    return par_count\n",
        "\n",
        "  # number of hidden layers to try\n",
        "  hidden_layers = ...\n",
        "\n",
        "  # test test score list\n",
        "  test_scores = []\n",
        "\n",
        "  for hidden_layer in hidden_layers:\n",
        "    # Initialize the hidden units in each hidden layer to be 1\n",
        "    hidden_units = np.ones(hidden_layer, dtype=np.int)\n",
        "\n",
        "    # Define the the with hidden units equal to 1\n",
        "    wide_net = Net('ReLU()', X_train.shape[1], hidden_units, K).to(device)\n",
        "    par_count = count_parameters(wide_net)\n",
        "\n",
        "    # increment hidden_units and repeat until the par_count reaches the desired count\n",
        "    while par_count < max_par_count:\n",
        "      hidden_units += 1\n",
        "      wide_net = Net('ReLU()', X_train.shape[1], hidden_units, K).to(device)\n",
        "      par_count = ...\n",
        "\n",
        "    # Train it\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(wide_net.parameters(), lr=1e-3)\n",
        "    _, test_acc = train_test_classification(wide_net, criterion, optimizer,\n",
        "                                            train_loader, test_loader,\n",
        "                                            num_epochs=100, device=device)\n",
        "    test_scores += [test_acc]\n",
        "\n",
        "  return hidden_layers, test_scores\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 1: Wide vs. Deep ')\n",
        "\n",
        "\n",
        "set_seed(seed=SEED)\n",
        "max_par_count = 100\n",
        "max_hidden_layer = 5\n",
        "## Uncomment below to test your function\n",
        "# hidden_layers, test_scores = run_depth_optimizer(max_par_count, max_hidden_layer, DEVICE)\n",
        "# plt.xlabel('# of hidden layers')\n",
        "# plt.ylabel('Test accuracy')\n",
        "# plt.plot(hidden_layers, test_scores)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "u9IkMbWwUfm8"
      },
      "source": [
        "## Think! 1: Why the tradeoff?\n",
        "Here we see that there is a particular number of hidden layers that is optimum. Why do you think increasing hidden layers after a certain point hurt in this scenario?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "heXbYjCJUfm9"
      },
      "source": [
        "## Section 1.1: Where Wide Fails\n",
        "Let's use the same Spiral dataset generated before with two features. And then add more polynomial features (which makes the first layer wider). And finally, train a single Linear layer. We could use the same MLP network with no hidden layers (though it would not be called an MLP anymore!).\n",
        "\n",
        "Note that we will add polynomial terms upto $P=50$ which means that for every $x_1^n x_2^m$ term, $n+m\\leq P$. Now it's fun math excercise to prove why the total number of polynomial features upto $P$ becomes,\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{# of terms} = \\frac{(P+1)(P+2)}{2}\n",
        "\\end{equation}\n",
        "\n",
        "Also, we don't need the polynomial term with degree zero (which is the constatnt term) since `nn.Linear` layers have bias terms. Therefore we will have one fewer polynomial feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "MRCk7gohUfm9"
      },
      "source": [
        "def run_poly_clasification(poly_degree, device='cpu', seed=0):\n",
        "\n",
        "  def make_poly_features(poly_degree, X):\n",
        "    # Define the number of polynomial features except the bias term\n",
        "    num_features = (poly_degree + 1)*(poly_degree + 2) // 2 - 1\n",
        "    poly_X = torch.zeros((X.shape[0], num_features))\n",
        "    count = 0\n",
        "    for i in range(poly_degree+1):\n",
        "      for j in range(poly_degree+1):\n",
        "         # no need to add zero degree since model has biases\n",
        "        if j + i > 0:\n",
        "          if j + i <= poly_degree:\n",
        "            # Define the polynomial term\n",
        "            poly_X[:, count] = X[:, 0]**i * X [:, 1]**j\n",
        "            count += 1\n",
        "    return poly_X, num_features\n",
        "\n",
        "  poly_X_test, num_features = make_poly_features(poly_degree, X_test)\n",
        "  poly_X_train, _ = make_poly_features(poly_degree, X_train)\n",
        "\n",
        "  batch_size = 128\n",
        "\n",
        "  g_seed = torch.Generator()\n",
        "  g_seed.manual_seed(seed)\n",
        "  poly_test_data = TensorDataset(poly_X_test, y_test)\n",
        "  poly_test_loader = DataLoader(poly_test_data,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=False,\n",
        "                                num_workers=1,\n",
        "                                worker_init_fn=seed_worker,\n",
        "                                generator=g_seed)\n",
        "\n",
        "  poly_train_data = TensorDataset(poly_X_train, y_train)\n",
        "  poly_train_loader = DataLoader(poly_train_data,\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=True,\n",
        "                                 num_workers=1,\n",
        "                                 worker_init_fn=seed_worker,\n",
        "                                 generator=g_seed)\n",
        "\n",
        "  # define a linear model using MLP class\n",
        "  poly_net = Net('ReLU()', num_features, [], K).to(device)\n",
        "\n",
        "  # Train it!\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(poly_net.parameters(), lr=1e-3)\n",
        "  _, _ = train_test_classification(poly_net, criterion, optimizer,\n",
        "                                   poly_train_loader, poly_test_loader,\n",
        "                                   num_epochs=100, device=DEVICE)\n",
        "  # Test it\n",
        "  X_all = sample_grid().to(device)\n",
        "  poly_X_all, _ = make_poly_features(poly_degree, X_all)\n",
        "  y_pred = poly_net(poly_X_all.to(device))\n",
        "\n",
        "  # Plot it\n",
        "  plot_decision_map(X_all.cpu(), y_pred.cpu(), X_test.cpu(), y_test.cpu())\n",
        "  plt.show()\n",
        "\n",
        "  return num_features\n",
        "\n",
        "\n",
        "set_seed(seed=SEED)\n",
        "max_poly_degree = 50\n",
        "num_features = run_poly_clasification(max_poly_degree, DEVICE, SEED)\n",
        "print(f'Number of features: {num_features}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gKjyHXFeUfm9"
      },
      "source": [
        "### Think! 1.1: Does it generalize well?\n",
        "Do you think this model is performing well outside its training distribution? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "9zgvh6V-Ufm-"
      },
      "source": [
        "---\n",
        "# Section 2: Deeper MLPs\n",
        "\n",
        "*Time estimate: ~55 mins*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "H8l90g2FUfm-",
        "cellView": "form"
      },
      "source": [
        "# @title Video 2: Case study\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1FL411n7SH\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"3g_OJ6dYE8E\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 2: Case study')\n",
        "\n",
        "# display(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "diMYcxbtUfm-"
      },
      "source": [
        "## Coding Exercise 2: Dataloader on a real-world dataset\n",
        "Let's build our first real-world dataset loader with Data Preprocessing and Augmentation! And we will use the Torchvision transforms to do it.\n",
        "\n",
        "We'd like to have a simple data augmentation with the following steps:\n",
        "* Random rotation with 10 degrees (`.RandomRotation`)\n",
        "* Random horizontal flipping (`.RandomHorizontalFlip`)\n",
        "\n",
        "and we'd like a preprocessing that:\n",
        "* makes Pytorch tensors in the range [0, 1] (`.ToTensor`)\n",
        "* normalizes the input in the range [-1, 1] (.`Normalize`)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Hint:** For more info on transform, see the [official documentation](https://pytorch.org/vision/stable/transforms.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "g8tfbtiaUfm-"
      },
      "source": [
        "def get_data_loaders(batch_size, seed):\n",
        "  ####################################################################\n",
        "  # Fill in all missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Define the get data loaders function\")\n",
        "  ###################################################################\n",
        "\n",
        "  # define the transform done only during training\n",
        "  augmentation_transforms = ...\n",
        "\n",
        "  # define the transform done in training and testing (after augmentation)\n",
        "  preprocessing_transforms = ...\n",
        "\n",
        "  # compose them together\n",
        "  train_transform = transforms.Compose(augmentation_transforms + preprocessing_transforms)\n",
        "  test_transform = transforms.Compose(preprocessing_transforms)\n",
        "\n",
        "  # using pathlib to be compatible with all OS's\n",
        "  data_path = pathlib.Path('.')/'afhq'\n",
        "\n",
        "  # define the dataset objects (they can load one by one)\n",
        "  img_train_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "  img_test_dataset = ImageFolder(data_path/'val', transform=test_transform)\n",
        "\n",
        "  g_seed = torch.Generator()\n",
        "  g_seed.manual_seed(seed)\n",
        "  # define the dataloader objects (they can load batch by batch)\n",
        "  img_train_loader = DataLoader(img_train_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=True,\n",
        "                                worker_init_fn=seed_worker,\n",
        "                                generator=g_seed)\n",
        "  # num_workers can be set to higher if running on Colab Pro TPUs to speed up,\n",
        "  # with more than one worker, it will do multithreading to queue batches\n",
        "  img_test_loader = DataLoader(img_test_dataset,\n",
        "                               batch_size=batch_size,\n",
        "                               shuffle=False,\n",
        "                               num_workers=1,\n",
        "                               worker_init_fn=seed_worker,\n",
        "                               generator=g_seed)\n",
        "\n",
        "  return img_train_loader, img_test_loader\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 2: Dataloader on a real-world dataset')\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "set_seed(seed=SEED)\n",
        "## Uncomment below to test your function\n",
        "# img_train_loader, img_test_loader = get_data_loaders(batch_size, SEED)\n",
        "## get some random training images\n",
        "# dataiter = iter(img_train_loader)\n",
        "# images, labels = dataiter.next()\n",
        "## show images\n",
        "# imshow(make_grid(images, nrow=8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "sOD4nkd1Ufm-"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D3_MultiLayerPerceptrons/solutions/W1D3_Tutorial2_Solution_9605a4e9.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=827.0 height=827.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D3_MultiLayerPerceptrons/static/W1D3_Tutorial2_Solution_9605a4e9_1.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "19QwOM6PUfm_"
      },
      "source": [
        "# Train it\n",
        "set_seed(seed=SEED)\n",
        "net = Net('ReLU()', 3*32*32, [64, 64, 64], 3).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
        "_, _ = train_test_classification(net, criterion, optimizer,\n",
        "                                img_train_loader, img_test_loader,\n",
        "                                num_epochs=30, device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "GAExs-a8Ufm_"
      },
      "source": [
        "# visualize the feature map\n",
        "fc1_weights = net.mlp[0].weight.view(64, 3, 32, 32).detach().cpu()\n",
        "fc1_weights /= torch.max(torch.abs(fc1_weights))\n",
        "imshow(make_grid(fc1_weights, nrow=8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tsvycNjcUfm_"
      },
      "source": [
        "## Think! 2: why first layer features are high level?\n",
        "Even though it's three layers deep, we see distinct animal faces in the first layer feature map. Do you think this MLP has a hierarchical feature representation? why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "ItvwAYBRUfm_"
      },
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q3', text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "QJmAmNAcUfm_"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D3_MultiLayerPerceptrons/solutions/W1D3_Tutorial2_Solution_eb2e554f.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "L7ubeHiBUfm_"
      },
      "source": [
        "---\n",
        "# Section 3: Ethical aspects\n",
        "\n",
        "*Time estimate: ~20 mins*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "xWtbq648Ufm_"
      },
      "source": [
        "# @title Video 3: Ethics: Hype in AI\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1CP4y1s712\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"ou35QzsKsdc\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 3: Ethics: Hype in AI')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "VvrynWPlUfnA"
      },
      "source": [
        "---\n",
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "VQ5Gvmb7UfnA"
      },
      "source": [
        "In the second tutorial of this day, we have dived deeper into MLPs and seen more of their mathematical and practical aspects. More specifically, we have learned about different architectures, i.e., deep, wide, and how they are dependent on the transfer function used. Also, we have learned about the importance of initialization, and we mathematically analyzed two methods for smart initialization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "7WxSAL89UfnA"
      },
      "source": [
        "---\n",
        "# Bonus: The need for good initialization\n",
        "\n",
        "In this section, we derive principles for initializing deep networks. We will see that if the weights are too large, then the forward propagation of signals will be chaotic, and the backpropagation of error gradients will explode. On the other hand, if the weights are too small, the forward propagation of signals will be ordered, and the backpropagation of error gradients will vanish. The key idea behind initialization is to choose the weights to be just right, i.e., at the edge between order and chaos. In this section, we derive this edge and show how to compute the correct initial variance of the weights. \n",
        "\n",
        "Many of the typical initialization schemes in existing deep learning frameworks implicitly employ this principle of initialization at the edge of chaos. So this section can be safely skipped on a first pass and **is a bonus section**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "Dq5IiX5TUfnA",
        "cellView": "form"
      },
      "source": [
        "# @title Video 5: Need for Good Initialization\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1Qq4y1H7Px\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"W0V2kwHSuUI\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 5: Need for Good Initialization')\n",
        "\n",
        "# display(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-51mKnQOUfnB"
      },
      "source": [
        "## Xavier initialization\n",
        "Let us look at the scale distribution of an output (e.g., a hidden variable)  $o_i$  for some fully-connected layer without nonlinearities. With  $n_{in}$  inputs  ($x_j$)  and their associated weights  $w_{ij}$  for this layer. Then an output is given by,\n",
        "\n",
        "\\begin{equation}\n",
        "o_{i} = \\sum_{j=1}^{n_\\mathrm{in}} w_{ij} x_j\n",
        "\\end{equation}\n",
        "\n",
        "The weights  $w_{ij}$  are all drawn independently from the same distribution. Furthermore, let us assume that this distribution has zero mean and variance  $\\sigma^2$ . Note that this does not mean that the distribution has to be Gaussian, just that the mean and variance need to exist. For now, let us assume that the inputs to the layer  $x_j$ also have zero mean and variance  $\\gamma^2$  and that they are independent of $w_{ij}$ and independent of each other. In this case, we can compute the mean and variance of $o_i$ as follows:\n",
        "\n",
        "\\begin{split}\n",
        "\\begin{aligned}\n",
        "    E[o_i] &= \\sum_{j=1}^{n_\\mathrm{in}} E[w_{ij} x_j] \\\\ \\\\ \n",
        "    &= \\sum_{j=1}^{n_\\mathrm{in}} E[w_{ij}] E[x_j] = 0, \\\\ \\\\ \\\\\n",
        "    \\mathrm{Var}[o_i] &= E[o_i^2] - (E[o_i])^2 \\\\ \\\\\n",
        "    &= \\sum_{j=1}^{n_\\mathrm{in}} E[w^2_{ij} x^2_j] - 0 \\\\ \\\\\n",
        "    &= \\sum_{j=1}^{n_\\mathrm{in}} E[w^2_{ij}] E[x^2_j] \\\\ \\\\\n",
        "    &= n_\\mathrm{in} \\sigma^2 \\gamma^2\n",
        "\\end{aligned}\n",
        "\\end{split}\n",
        "\n",
        "One way to keep the variance fixed is to set $n_{in}\\sigma^2=1$ . Now consider backpropagation. There we face a similar problem, albeit with gradients being propagated from the layers closer to the output. Using the same reasoning as for forward propagation, we see that the gradients variance can blow up unless $n_{out}\\sigma^2=1$ , where  $n_{out}$ is the number of outputs of this layer. This leaves us in a dilemma: we cannot possibly satisfy both conditions simultaneously. Instead, we simply try to satisfy:\n",
        "\n",
        "\\begin{aligned}\n",
        "\\frac{1}{2} (n_\\mathrm{in} + n_\\mathrm{out}) \\sigma^2 = 1 \\text{ or equivalently }\n",
        "\\sigma = \\sqrt{\\frac{2}{n_\\mathrm{in} + n_\\mathrm{out}}}\n",
        "\\end{aligned}\n",
        "\n",
        "This is the reasoning underlying the now-standard and practically beneficial Xavier initialization, named after the first author of its creators [Glorot & Bengio, 2010]. Typically, the Xavier initialization samples weights from a Gaussian distribution with zero mean and variance  $\\sigma^2=\\frac{2}{(n_{in}+n_{out})}$,\n",
        "\n",
        "\\begin{equation}\n",
        "w_{ij} \\sim \\mathcal{N} \\left (\\mu=0, \\sigma=\\sqrt{\\frac{2}{(n_{in}+n_{out})}} \\right)\n",
        "\\end{equation}\n",
        "\n",
        "We can also adapt Xaviers intuition to choose the variance when sampling weights from a uniform distribution. Note that the uniform distribution $U(a,a)$ has variance $\\frac{a^2}{3}$. Plugging this into our condition on $\\sigma^2$ yields the suggestion to initialize according to\n",
        "\n",
        "\\begin{equation}\n",
        "w_{ij} \\sim  \\mathcal{U} \\left(-\\sqrt{\\frac{6}{n_\\mathrm{in} + n_\\mathrm{out}}}, \\sqrt{\\frac{6}{n_\\mathrm{in} + n_\\mathrm{out}}}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "This explanation is mainly taken from [here](https://d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "MVPUFBuEUfnB"
      },
      "source": [
        "If you want to see more about initializations and their differences see [here](https://www.deeplearning.ai/ai-notes/initialization/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "2_4UnhVSUfnB"
      },
      "source": [
        "## Initialization with transfer function\n",
        "Let's derive the optimal gain for LeakyReLU following similar steps.\n",
        "\n",
        "LeakyReLU is described mathematically:\n",
        "\n",
        "\\begin{equation}\n",
        "f(x)=\\left\\{\n",
        "  \\begin{array}{ll}\n",
        "    \\alpha \\cdot x & \\text { for } x<0 \\\\\n",
        "    x & \\text { for } x \\geq 0\n",
        "  \\end{array}\\right.\n",
        "\\end{equation}\n",
        "\n",
        "where $\\alpha$ controls the angle of the negative slope.\n",
        "\n",
        "Considering a single layer with this activation function gives,\n",
        "\n",
        "\\begin{align}\n",
        "o_{i} &= \\sum_{j=1}^{n_\\mathrm{in}} w_{ij} x_j\\\\\n",
        "z_{i} &= f\\left( o_{i} \\right)\n",
        "\\end{align}\n",
        "\n",
        "where $z_i$ denotes the activation of node $i$.\n",
        "\n",
        "The expectation of the output is still zero, i.e., $\\mathbb{E}[f(o_i)=0]$, but the variance changes, and assuming that the probability $P(x < 0) = 0.5$, we have that:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\mathrm{Var}[f(o_i)] &= \\mathbb{E}[f(o_i)^2] - \\left( \\mathbb{E}[f(o_i)] \\right)^{2} \\\\ \\\\\n",
        "&= \\frac{\\mathrm{Var}[o_i] + \\alpha^2 \\mathrm{Var}[o_i]}{2} \\\\ \\\\\n",
        "&= \\frac{1+\\alpha^2}{2}n_\\mathrm{in} \\sigma^2 \\gamma^2\n",
        "\\end{align}\n",
        "\n",
        "where $\\gamma$ is the variance of the distribution of the inputs $x_j$ and $\\sigma$ is the variance of the distribution of weights $w_{ij}$, as before.\n",
        "\n",
        "Therefore, following the rest of derivation as before,\n",
        "\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma = gain\\sqrt{\\frac{2}{n_\\mathrm{in} + n_\\mathrm{out}}}, \\, \\text{where} \\,\\, gain = \\sqrt{\\frac{2}{1+\\alpha^2}}\n",
        "\\end{equation}\n",
        "\n",
        "As we can see from the derived formula of $\\sigma$, the transfer function we choose is related with the variance of the distribution of the weights. As the negative slope of the LeakyReLU $\\alpha$ becomes larger, the $gain$ becomes smaller and thus, the distribution of the weights is narrower. On the other hand, as $\\alpha$ becomes smaller and smaller, the distribution of the weights is wider. Recall that, we initialize our weights, for example, by sampling from a normal distribution with zero mean and variance $\\sigma^2$, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "sD7O46hPUfnB"
      },
      "source": [
        "## Best gain for Xavier Initialization with Leaky ReLU\n",
        "You're probably running out of time, so let me explain what's happening here. We derived a theoretical gain for initialization. But the question is whether it holds in practice? Here we have a setup to confirm our finding. We will try a range of gains and see the empirical optimum and whether it matches our theoretical value!\n",
        "\n",
        "If you have time left, you can change the distribution to sample the initial weights from a uniform distribution. Comment out line 11 and uncomment line 12."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "Ar6JwjVSUfnB"
      },
      "source": [
        "N = 10  # number of trials\n",
        "gains = np.linspace(1/N, 3.0, N)\n",
        "test_accs = []\n",
        "train_accs = []\n",
        "mode = 'uniform'\n",
        "for gain in gains:\n",
        "  print(f'\\ngain: {gain}')\n",
        "\n",
        "  def init_weights(m, mode='normal'):\n",
        "    if type(m) == nn.Linear:\n",
        "      torch.nn.init.xavier_normal_(m.weight, gain)\n",
        "      # torch.nn.init.xavier_uniform_(m.weight, gain)\n",
        "\n",
        "  negative_slope = 0.1\n",
        "  actv = f'LeakyReLU({negative_slope})'\n",
        "  set_seed(seed=SEED)\n",
        "  net = Net(actv, 3*32*32, [128, 64, 32], 3).to(DEVICE)\n",
        "  net.apply(init_weights)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  optimizer = optim.SGD(net.parameters(), lr=1e-2)\n",
        "  train_acc, test_acc = train_test_classification(net, criterion, optimizer,\n",
        "                                                  img_train_loader,\n",
        "                                                  img_test_loader,\n",
        "                                                  num_epochs=1,\n",
        "                                                  verbose=True,\n",
        "                                                  device=DEVICE)\n",
        "  test_accs += [test_acc]\n",
        "  train_accs += [train_acc]\n",
        "\n",
        "best_gain = gains[np.argmax(train_accs)]\n",
        "plt.plot(gains, test_accs, label='Test accuracy')\n",
        "plt.plot(gains, train_accs, label='Train accuracy')\n",
        "plt.scatter(best_gain, max(train_accs),\n",
        "            label=f'best gain={best_gain:.1f}',\n",
        "            c='k', marker ='x')\n",
        "# calculate and plot the theoretical gain\n",
        "theoretical_gain = np.sqrt(2.0 / (1 + negative_slope ** 2))\n",
        "plt.scatter(theoretical_gain, max(train_accs),\n",
        "            label=f'theoretical gain={theoretical_gain:.2f}',\n",
        "            c='g', marker ='x')\n",
        "plt.legend()\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}